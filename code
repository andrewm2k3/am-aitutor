import os
import re
import ast
from openai import OpenAI
from dotenv import load_dotenv
load_dotenv()

client = OpenAI(api_key=os.environ.get("OPEN_AI_KEY"))

vocabulary_list = set() # will store unique words used by user
user_responses = [] # stores user's full-text responses to questions

# keeping for now, make prompt more specific to language / mention {target_language}
# mention specific kinds of questions -- not necessarily open-ended (maybe some questions (i.e., 2 of 5) are free response so that user can add words to vocabulary_list, but others should have correct/incorrect answers

def generate_questions(essay_text, target_language, num_questions):
    system_prompt = f"""
    You are an exam administrator evaluating whether a student has authentically engaged with their written work by generating insightful, personalized questions based on the essay. To do this, craft open-ended questions that delve into the unique perspectives and deeper understanding the student may have developed. Using Fink's model of learning, focus specifically on the Human Dimension. Select key quotes from the essay and build follow-up questions around them that would encourage the author to expand on their thoughts or reasoning. Your questions should be designed to prompt responses that would likely only come from the individual who wrote the piece, showcasing their unique insight or learning journey. You want them to provide real-world examples when possible. Make sure to have only one question mark per question.
    Generate {num_questions} questions.
    Format:
    Question 1: <text>
    Question 2: <text>
    ...
    """

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": essay_text}
        ],
        temperature=0.7, # recommended temperature between 0.5 and 0.7 for educational prompts
        max_tokens=1000
    )

    questions_text = response.choices[0].message.content
    questions = []

    for line in questions_text.strip().split("\n"):
        if line.strip().startswith("Question"):
            parts = line.split(":", 1)
            if len(parts) > 1:
                q = parts[1].strip()
                questions.append(q)

    return questions

def process_user_response(response_text, target_language):
    user_responses.append(response_text)
    words = re.findall(r'\b\w+\b', response_text.lower())
    validation_prompt = f"""
    add prompt
    """

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": validation_prompt}
        ],
        temperature=0.2, # lower temperature for more strict filtering
        max_tokens=300
    )

    try:
        valid_words = ast.literal_eval(response.choices[0].message.content.strip())
        vocabulary_list.update(valid_words)
    except Exception as e:
        print("Error parsing vocabulary:", e)
        print("Response was:", response.choices[0].message.content)

def generate_known_vocab_text(topic, target_language):
    if not vocabulary_list:
        return "no words in vocab list"

    vocab_string = ", ".join(sorted(vocabulary_list))

    prompt = f"""
    The user is learning {target_language} and knows these words:
    {vocab_string}

    Please write a short, coherent paragraph about the subject "{topic}" using only these words.
    You may inflect the words, but do not introduce any new vocabulary unless absolutely necessary.
    Keep the grammar simple and friendly to beginners.
    """

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": prompt}
        ],
        temperature=0.7,
        max_tokens=300
    )

    return response.choices[0].message.content.strip()
